"""Module for summarizing clusters using OpenAI API."""

from __future__ import annotations

import os
from typing import List, Tuple

from openai import OpenAI

# Initialize client lazily to allow module import without API key
_client = None

def get_client() -> OpenAI:
    global _client
    if _client is None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise RuntimeError("OPENAI_API_KEY environment variable is not set")
        _client = OpenAI(api_key=api_key)
    return _client


def summarize_cluster(
    representative_texts: List[str],
    video_title: str | None = None,
) -> Tuple[str, str, str]:
    """
    Generate a label, summary, and stance for a cluster of comments.

    Args:
        representative_texts: List of representative comment strings
        video_title: Title of the video (optional context)

    Returns:
        Tuple of (label, summary, stance)
        - label: Short topic name (8-18 chars)
        - summary: 2-3 sentence summary
        - stance: 'support', 'skeptic', or 'neutral'
    """
    client = get_client()
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # Take top 5 for context
    joined = "\n".join([f"- {t}" for t in representative_texts[:5]])

    system = (
        "ã‚ãªãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆã®è«–ç‚¹ã‚’çŸ­ãæ•´ç†ã™ã‚‹ç·¨é›†è€…ã§ã™ã€‚"
        "æ›–æ˜§ãªä¸€èˆ¬è«–ã§ã¯ãªãã€ã‚³ãƒ¡ãƒ³ãƒˆã«å®Ÿéš›ã«å«ã¾ã‚Œã‚‹ä¸»å¼µã ã‘ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
        "éåº¦ã«æ–­å®šã›ãšã€ã‚³ãƒ¡ãƒ³ãƒˆã®ãƒˆãƒ¼ãƒ³ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚"
    )

    user = f"""
å¯¾è±¡: YouTubeå‹•ç”»ã‚³ãƒ¡ãƒ³ãƒˆã®ä»£è¡¨ä¾‹ï¼ˆæœ€å¤§5ä»¶ï¼‰
å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title or "ä¸æ˜"}

ä»£è¡¨ã‚³ãƒ¡ãƒ³ãƒˆ:
{joined}

å‡ºåŠ›å½¢å¼ï¼ˆå³å®ˆï¼‰:
LABEL: <çŸ­ã„è«–ç‚¹å>
SUMMARY: <2ã€œ3æ–‡ã®è¦ç´„>
STANCE: <support|skeptic|neutral> (å‹•ç”»å†…å®¹ã«å¯¾ã—ã¦è‚¯å®šçš„=support, æ‡ç–‘çš„/æ‰¹åˆ¤çš„=skeptic, ä¸­ç«‹/ãã®ä»–=neutral)
""".strip()

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.3,
            max_tokens=300,
        )

        text = resp.choices[0].message.content or ""
        label = ""
        summary = ""
        stance = "neutral"

        # Parse output
        for line in text.splitlines():
            line = line.strip()
            if line.startswith("LABEL:"):
                label = line.replace("LABEL:", "").strip()
            elif line.startswith("SUMMARY:"):
                summary = line.replace("SUMMARY:", "").strip()
            elif line.startswith("STANCE:"):
                parsed_stance = line.replace("STANCE:", "").strip().lower()
                if parsed_stance in ["support", "skeptic", "neutral"]:
                    stance = parsed_stance

        # Fallback if parsing failed
        if not label:
            # If AI didn't follow format, try to use first line as label or generic
            cleaned_text = text.replace("LABEL:", "").strip()
            label = cleaned_text.split("\n")[0][:20] if cleaned_text else "è«–ç‚¹"
        
        if not summary:
            # Use the whole text if summary tag missing
            summary = text.replace("SUMMARY:", "").strip()[:200]

        return label, summary, stance

    except Exception as e:
        print(f"[summarize] Error generating summary: {e}")
        return "è«–ç‚¹ï¼ˆç”Ÿæˆã‚¨ãƒ©ãƒ¼ï¼‰", "è¦ç´„ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚", "neutral"


def summarize_overall(
    clusters_data: List[dict],
    video_title: str | None = None,
) -> str | None:
    """
    Generate an overall summary from all cluster labels and summaries.

    Args:
        clusters_data: List of dicts with 'label', 'summary', 'size' keys
        video_title: Title of the video (optional context)

    Returns:
        Overall summary as markdown-formatted string with key points, or None if failed
    """
    if not clusters_data:
        return None

    client = get_client()
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # Format cluster info
    cluster_info = "\n".join([
        f"- {c['label']} ({c['size']}ä»¶): {c['summary']}"
        for c in clusters_data
    ])

    system = (
        "ã‚ãªãŸã¯YouTubeå‹•ç”»ã®ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æçµæœã‚’è¦ç´„ã™ã‚‹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"
        "å„ã‚¯ãƒ©ã‚¹ã‚¿ã®è«–ç‚¹ã‚’çµ±åˆã—ã€è¦–è´è€…ã®åå¿œã®å…¨ä½“åƒã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
        "å…·ä½“çš„ãªæ„è¦‹å†…å®¹ã‚’å«ã‚ã€èª­è€…ãŒã™ãã«ç†è§£ã§ãã‚‹å½¢ã«ã—ã¦ãã ã•ã„ã€‚"
    )

    user = f"""
å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title or "ä¸æ˜"}

ã‚³ãƒ¡ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã®åˆ†æçµæœ:
{cluster_info}

ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

## ã‚³ãƒ¡ãƒ³ãƒˆã®è¦ç‚¹
- è¦ç‚¹1ï¼ˆå…·ä½“çš„ãªå†…å®¹ï¼‰
- è¦ç‚¹2ï¼ˆå…·ä½“çš„ãªå†…å®¹ï¼‰
- è¦ç‚¹3ï¼ˆå…·ä½“çš„ãªå†…å®¹ï¼‰

## è«–ç‚¹ã®å‚¾å‘
ï¼ˆè³›æˆ/åå¯¾/ä¸­ç«‹ã®å‚¾å‘ã‚„ã€ç‰¹ã«å¤šã„æ„è¦‹ã«ã¤ã„ã¦1ã€œ2æ–‡ã§ï¼‰
""".strip()

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.3,
            max_tokens=500,
        )

        result = resp.choices[0].message.content or ""
        return result.strip()

    except Exception as e:
        print(f"[summarize] Error generating overall summary: {e}")
        return None


def summarize_issue_outline(
    clusters_data: List[dict],
    video_title: str | None = None,
    video_summary: str | None = None,
) -> str | None:
    """
    Generate a structured issue outline (issues, disputes, agreements, unanswered questions).

    Args:
        clusters_data: List of dicts with 'label', 'summary', 'size', 'stance' keys
        video_title: Title of the video (optional context)
        video_summary: Summary of the video content (optional context)

    Returns:
        Markdown string with structured issue outline, or None if failed
    """
    if not clusters_data:
        return None

    client = get_client()
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # Format cluster info
    cluster_info = "\n".join([
        f"- {c['label']} ({c['size']}ä»¶, {c['stance']}): {c['summary']}"
        for c in clusters_data
    ])

    system = (
        "ã‚ãªãŸã¯å‹•ç”»ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã™ã‚‹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚"
        "ã‚³ãƒ¡ãƒ³ãƒˆç¾¤ã‹ã‚‰ã€Œä¸»è¦è«–ç‚¹ã€ã€Œä½•ãŒå¯¾ç«‹ã—ã¦ã„ã‚‹ã‹ï¼ˆäº‰ç‚¹ï¼‰ã€ã€Œä½•ãŒåˆæ„ã•ã‚Œã¦ã„ã‚‹ã‹ï¼ˆåˆæ„ç‚¹ï¼‰ã€ã€Œæœªè§£æ±ºã®å•ã„ã€ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚"
        "å‹•ç”»å†…å®¹ã®è¦ç´„ã‚‚æä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã‚³ãƒ¡ãƒ³ãƒˆãŒå‹•ç”»ã®ã©ã®éƒ¨åˆ†ã«åå¿œã—ã¦ã„ã‚‹ã‹ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚"
    )

    user = f"""
å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {video_title or "ä¸æ˜"}
å‹•ç”»å†…å®¹ã®è¦ç´„: {video_summary or "ãªã—"}

ã‚³ãƒ¡ãƒ³ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã®åˆ†æçµæœ:
{cluster_info}

ä»¥ä¸‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³å½¢å¼ã§ã€Markdownã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆè¦‹å‡ºã—ã¯ ## ã‚’ä½¿ç”¨ï¼‰:

## ğŸ“Œ ä¸»è¦è«–ç‚¹
ï¼ˆè­°è«–ã®ä¸­å¿ƒã¨ãªã£ã¦ã„ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚’3ã€œ6å€‹ç¨‹åº¦ã€‚å„1è¡Œã‚¿ã‚¤ãƒˆãƒ«ï¼‹2ã€œ3è¡Œã®èª¬æ˜ï¼‰

## âš”ï¸ äº‰ç‚¹ï¼ˆå¯¾ç«‹ãƒã‚¤ãƒ³ãƒˆï¼‰
ï¼ˆè‚¯å®šæ´¾ã¨æ‡ç–‘æ´¾ã§æ„è¦‹ãŒåˆ†ã‹ã‚Œã¦ã„ã‚‹ç‚¹ã€‚å…·ä½“çš„ã«ã©ã“ã§å¯¾ç«‹ã—ã¦ã„ã‚‹ã‹ï¼‰

## ğŸ¤ åˆæ„ç‚¹ãƒ»å…±é€šèªè­˜
ï¼ˆã‚¹ã‚¿ãƒ³ã‚¹ã«é–¢ã‚ã‚‰ãšå¤šãã®äººãŒåŒæ„ã—ã¦ã„ã‚‹ç‚¹ã€ã¾ãŸã¯å‰æã¨ã—ã¦å…±æœ‰ã•ã‚Œã¦ã„ã‚‹äº‹å®Ÿï¼‰

## â“ æœªè§£æ±ºã®å•ã„ãƒ»æ®‹ã•ã‚ŒãŸèª²é¡Œ
ï¼ˆçµè«–ãŒå‡ºã¦ã„ãªã„ç–‘å•ã€è¨¼æ‹ ä¸è¶³ã®æŒ‡æ‘˜ã€ä»Šå¾Œã®æ‡¸å¿µç‚¹ãªã©ï¼‰
""".strip()

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.3,
            max_tokens=800,
        )

        result = resp.choices[0].message.content or ""
        return result.strip()

    except Exception as e:
        print(f"[summarize] Error generating issue outline: {e}")
        return None


def summarize_video_content(
    transcript_text: str,
    title: str = "",
    description: str = "",
) -> str | None:
    """
    Generate a summary of the video content based on transcript (or description).
    """
    if not transcript_text and not description:
        return None

    client = get_client()
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    # Access text limit (truncate if too long)
    # gpt-4o-mini context is large (128k), but let's limit to ~15k chars to be safe and fast
    limit = 15000
    context_text = transcript_text[:limit]
    if len(transcript_text) > limit:
        context_text += "...(truncated)"
    
    system = (
        "ã‚ãªãŸã¯å‹•ç”»ã®å†…å®¹ã‚’è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "æä¾›ã•ã‚ŒãŸå­—å¹•ï¼ˆã¾ãŸã¯èª¬æ˜æ–‡ï¼‰ã‚’ã‚‚ã¨ã«ã€å‹•ç”»ã§èªã‚‰ã‚Œã¦ã„ã‚‹ä¸»è¦ãªå†…å®¹ã€çµè«–ã€ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãªã©ã‚’300æ–‡å­—ç¨‹åº¦ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
    )

    user = f"""
å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {title}
èª¬æ˜æ–‡: {description[:500]}

å­—å¹•ãƒ‡ãƒ¼ã‚¿:
{context_text}

è¦ç´„:
""".strip()

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            temperature=0.3,
            max_tokens=400,
        )

        return (resp.choices[0].message.content or "").strip()

    except Exception as e:
        print(f"[summarize] Error generating video summary: {e}")
        return None
